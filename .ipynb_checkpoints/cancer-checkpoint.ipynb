{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is from the website below\n",
    "#https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "df_pre = pd.read_csv(\"data.csv\")\n",
    "df_pre = df_pre.loc[:, ~df_pre.columns.str.contains('^Unnamed')]\n",
    "#Took out a column that was called Unnamed and had no data in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose a dataset that dealt with breast cancer. Essentially there are a lot of varibles that were measured for individuals and we are trying to see how these measurements correlate to someone having a malignant tumor.\n",
    "\n",
    "According to breastcancer.org 1 in 8 women develop invasive breast cancer over their lifetime.\n",
    "\n",
    "Due to the infamousy of breast cancer we wanted to see of we could use classification algoritms \n",
    "to determine if an individual has a malignant tumor based on pre measured variabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_Malignant</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_Malignant  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          True        17.99         10.38          122.80     1001.0   \n",
       "1          True        20.57         17.77          132.90     1326.0   \n",
       "2          True        19.69         21.25          130.00     1203.0   \n",
       "3          True        11.42         20.38           77.58      386.1   \n",
       "4          True        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"is_Malignant\"] = df_pre[\"diagnosis\"].apply(lambda x: bool(x=='M'))\n",
    "for var in df_pre.select_dtypes(include='float'):\n",
    "    df[var] = df_pre[var].apply(lambda x: float(x))\n",
    "\n",
    "df.head()\n",
    "#Made is_Malignant a bool for when the value in the predefined \"diagnosis\" column was \"M\"\n",
    "#The diagnosis column turned into \"is_Malignant\" and has a value of true if \"M\" and flase otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "for var in df.columns:\n",
    "    if len(df[var]) != len(df[var].dropna()):\n",
    "        print(var)\n",
    "print('Done')\n",
    "#Check to see if there are any na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoothness_se             -0.067016\n",
       "fractal_dimension_mean    -0.012838\n",
       "texture_se                -0.008303\n",
       "symmetry_se               -0.006522\n",
       "fractal_dimension_se       0.077972\n",
       "concavity_se               0.253730\n",
       "compactness_se             0.292999\n",
       "fractal_dimension_worst    0.323872\n",
       "symmetry_mean              0.330499\n",
       "smoothness_mean            0.358560\n",
       "concave points_se          0.408042\n",
       "texture_mean               0.415185\n",
       "symmetry_worst             0.416294\n",
       "smoothness_worst           0.421465\n",
       "texture_worst              0.456903\n",
       "area_se                    0.548236\n",
       "perimeter_se               0.556141\n",
       "radius_se                  0.567134\n",
       "compactness_worst          0.590998\n",
       "compactness_mean           0.596534\n",
       "concavity_worst            0.659610\n",
       "concavity_mean             0.696360\n",
       "area_mean                  0.708984\n",
       "radius_mean                0.730029\n",
       "area_worst                 0.733825\n",
       "perimeter_mean             0.742636\n",
       "radius_worst               0.776454\n",
       "concave points_mean        0.776614\n",
       "perimeter_worst            0.782914\n",
       "concave points_worst       0.793566\n",
       "is_Malignant               1.000000\n",
       "Name: is_Malignant, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['is_Malignant'].sort_values()\n",
    "# Output of correlation of each feature compared to is_Malignant sorted from highest to \n",
    "# lowest so we can get some idea of what features have high correlation.\n",
    "# This part gave us a lot insight for what features would correspond to the outcome of having a malignant tumor\n",
    "# Suprisingly there were only 5 features that had correlation under 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    357\n",
       "True     212\n",
       "Name: is_Malignant, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"is_Malignant\"].value_counts().plot(kind=\"bar\")\n",
    "df[\"is_Malignant\"].value_counts()\n",
    "# Plot to easily see how many individuals have a malignant tumor or a benign tumor\n",
    "# 357 had a benign and 212 had a malignant tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malig(var):\n",
    "    figure = plt.figure(figsize = (25,7))\n",
    "    plt.hist([df[df[\"is_Malignant\"] == 1][var], df[df[\"is_Malignant\"] == 0][var]],\n",
    "            stacked = True, color =['g','r'],bins = 50, label = [\"Malignant\",\"Benign\"])\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel(\"Number of Individuals\")\n",
    "    plt.legend();\n",
    "# function to plot the number of inidvuduals who have a specified feature, and with that feature either have a \n",
    "# malignant tumor or a benign tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "malig(\"concave points_worst\")\n",
    "# malig function with concave points_worst feature as variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "malig(\"area_mean\")\n",
    "# malig function with area_mean feature as variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_Malignant  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0            True     0.521037      0.022658        0.545989   0.363733   \n",
      "1            True     0.643144      0.272574        0.615783   0.501591   \n",
      "2            True     0.601496      0.390260        0.595743   0.449417   \n",
      "3            True     0.210090      0.360839        0.233501   0.102906   \n",
      "4            True     0.629893      0.156578        0.630986   0.489290   \n",
      "..            ...          ...           ...             ...        ...   \n",
      "564          True     0.690000      0.428813        0.678668   0.566490   \n",
      "565          True     0.622320      0.626987        0.604036   0.474019   \n",
      "566          True     0.455251      0.621238        0.445788   0.303118   \n",
      "567          True     0.644564      0.663510        0.665538   0.475716   \n",
      "568         False     0.036869      0.501522        0.028540   0.015907   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0           0.593753          0.792037        0.703140             0.731113   \n",
      "1           0.289880          0.181768        0.203608             0.348757   \n",
      "2           0.514309          0.431017        0.462512             0.635686   \n",
      "3           0.811321          0.811361        0.565604             0.522863   \n",
      "4           0.430351          0.347893        0.463918             0.518390   \n",
      "..               ...               ...             ...                  ...   \n",
      "564         0.526948          0.296055        0.571462             0.690358   \n",
      "565         0.407782          0.257714        0.337395             0.486630   \n",
      "566         0.288165          0.254340        0.216753             0.263519   \n",
      "567         0.588336          0.790197        0.823336             0.755467   \n",
      "568         0.000000          0.074351        0.000000             0.000000   \n",
      "\n",
      "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.686364  ...      0.620776       0.141525         0.668310   \n",
      "1         0.379798  ...      0.606901       0.303571         0.539818   \n",
      "2         0.509596  ...      0.556386       0.360075         0.508442   \n",
      "3         0.776263  ...      0.248310       0.385928         0.241347   \n",
      "4         0.378283  ...      0.519744       0.123934         0.506948   \n",
      "..             ...  ...           ...            ...              ...   \n",
      "564       0.336364  ...      0.623266       0.383262         0.576174   \n",
      "565       0.349495  ...      0.560655       0.699094         0.520892   \n",
      "566       0.267677  ...      0.393099       0.589019         0.379949   \n",
      "567       0.675253  ...      0.633582       0.730277         0.668310   \n",
      "568       0.266162  ...      0.054287       0.489072         0.043578   \n",
      "\n",
      "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      0.450698          0.601136           0.619292         0.568610   \n",
      "1      0.435214          0.347553           0.154563         0.192971   \n",
      "2      0.374508          0.483590           0.385375         0.359744   \n",
      "3      0.094008          0.915472           0.814012         0.548642   \n",
      "4      0.341575          0.437364           0.172415         0.319489   \n",
      "..          ...               ...                ...              ...   \n",
      "564    0.452664          0.461137           0.178527         0.328035   \n",
      "565    0.379915          0.300007           0.159997         0.256789   \n",
      "566    0.230731          0.282177           0.273705         0.271805   \n",
      "567    0.402035          0.619626           0.815758         0.749760   \n",
      "568    0.020497          0.124084           0.036043         0.000000   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.912027        0.598462                 0.418864  \n",
      "1                0.639175        0.233590                 0.222878  \n",
      "2                0.835052        0.403706                 0.213433  \n",
      "3                0.884880        1.000000                 0.773711  \n",
      "4                0.558419        0.157500                 0.142595  \n",
      "..                    ...             ...                      ...  \n",
      "564              0.761512        0.097575                 0.105667  \n",
      "565              0.559450        0.198502                 0.074315  \n",
      "566              0.487285        0.128721                 0.151909  \n",
      "567              0.910653        0.497142                 0.452315  \n",
      "568              0.000000        0.257441                 0.100682  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "regressionFeatures = df.select_dtypes(include='float').columns\n",
    "df_regressionFeatures = pd.DataFrame(data=MinMaxScaler().fit_transform(df[regressionFeatures]), columns=regressionFeatures)\n",
    "\n",
    "dfFull = pd.concat([df[['is_Malignant']], df_regressionFeatures], axis=1)\n",
    "print(dfFull)\n",
    "#Setting the regression features as the features that are floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7S_CMDNUNoa"
   },
   "outputs": [],
   "source": [
    "features = dfFull.columns.drop([\"is_Malignant\"])\n",
    "target = 'is_Malignant'\n",
    "#Took out is_Malignant for testing with algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we used the classification algoritms with all the features to see what kind of scores we would get. We thought of only using features above 25% correlation but decided to use all of them to see what the output would be.\n",
    "Suprisingly we got very high percentages with leaving all the features in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlw2jMjXUNoh"
   },
   "outputs": [],
   "source": [
    "lenTrain, lenVal = 200, 150\n",
    "seed = 42\n",
    "train, test = train_test_split(dfFull, random_state=seed, test_size=len(dfFull)-lenTrain-lenVal)\n",
    "train, val = train_test_split(train, random_state=seed, test_size=lenVal)\n",
    "#Split the training, testing and validation sets using a random_state.\n",
    "#Uses a dev set to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMXP59YnUNok"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = train[features], val[features], test[features]\n",
    "y_train, y_val, y_test = train[target], val[target], test[target]\n",
    "#Set the train, val, and test input and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOanjBgDUNoo"
   },
   "outputs": [],
   "source": [
    "lin, linParam = SGDClassifier(random_state=42), {'max_iter': [800, 900, 1000, 1100, 1200]}\n",
    "knn, knnParam = KNeighborsClassifier(), {'n_neighbors': range(1, 100, 3), 'weights': ['uniform','distance']}\n",
    "tree, treeParam = DecisionTreeClassifier(random_state=42), {}\n",
    "gnb, gnbParam = GaussianNB(), {}\n",
    "svm, svmParam = SVC(random_state=42, gamma='auto'), {'C': [1, 10, 100, 1000], 'kernel': ['rbf', 'linear']}\n",
    "rfc, rfcParam = RandomForestClassifier(), {'n_estimators': [5, 10, 15], 'criterion': ['entropy', 'gini'], 'max_depth': [2, 3, 5, 10], \n",
    "                                           'min_samples_split': [2, 3, 5], 'min_samples_leaf': [1, 5, 8]}\n",
    "abc, abcParam = AdaBoostClassifier(random_state=42), {'n_estimators': range(1, 100, 10)}\n",
    "bc, bcParam = BaggingClassifier(random_state=42), {'base_estimator': [svm, knn, tree], 'n_estimators': range(1, 100, 10)}\n",
    "classifiers = [[lin, linParam], [knn, knnParam], [tree, treeParam], [gnb, gnbParam], [svm, svmParam], \n",
    "               [rfc, rfcParam], [abc, abcParam], [bc, bcParam]]\n",
    "#Set up the algorithms for use with parameters we chose, also chose our classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F42CJjJSUNos",
    "outputId": "9dffee08-ed37-43fd-d27b-b74756883680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=800, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "0.9294210526315788\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
      "                     weights='uniform')\n",
      "1.0\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best')\n",
      "0.920436753648828\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "0.9375796568627451\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "1.0\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.9882352941176471\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=81, random_state=42)\n",
      "0.9745\n",
      "BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto',\n",
      "                                                      leaf_size=30,\n",
      "                                                      metric='minkowski',\n",
      "                                                      metric_params=None,\n",
      "                                                      n_jobs=None,\n",
      "                                                      n_neighbors=5, p=2,\n",
      "                                                      weights='uniform'),\n",
      "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=51, n_jobs=None,\n",
      "                  oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False)\n",
      "0.9875\n",
      "The top three estimators:\n",
      "[SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
      "                     weights='uniform'), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)]\n",
      "[1.0, 1.0, 0.9882352941176471]\n"
     ]
    }
   ],
   "source": [
    "topEstimator = [None, None, None]\n",
    "topScores = [0, 0, 0]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    grid = GridSearchCV(\n",
    "        estimator=classifier[0], param_grid=classifier[1],\n",
    "        scoring=\"precision\", cv=5,\n",
    "        iid=True\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    for i in range(0, len(topScores)):\n",
    "        if grid.best_score_ > topScores[i]:\n",
    "            if i != len(topScores)-1 and topScores[i] > topScores[i+1]:\n",
    "                continue\n",
    "            else:\n",
    "                topEstimator[i] = grid.best_estimator_\n",
    "                topScores[i] = grid.best_score_\n",
    "                break\n",
    "    \n",
    "    print (grid.best_estimator_)\n",
    "    print (grid.best_score_)\n",
    "    \n",
    "print('The top three estimators:')\n",
    "print(topEstimator)\n",
    "print(topScores)\n",
    "# Used gridsearch with the algorithms we picked, with a loop that printed the top estimator with its corresponing best score.\n",
    "# Our best three algoritms were SVC, KNeighborsClassifier, and RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jU9G_g9gUNow"
   },
   "outputs": [],
   "source": [
    "corr_matrix = df.corr().loc[df.corr()['is_Malignant'] == 1].abs()\n",
    "\n",
    "to_drop = []\n",
    "for column in corr_matrix.columns:\n",
    "    if float(corr_matrix[[column]].loc['is_Malignant']) < .25:\n",
    "        to_drop.append(column)\n",
    "\n",
    "feat_select = X_train.columns.drop(to_drop)\n",
    "\n",
    "X_feat_train, X_feat_val, X_feat_test = X_train[feat_select], X_val[feat_select], X_test[feat_select]\n",
    "#Took out any features that had less than a 25% correlation to is_Malignant to see how the scores would change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PldVlBb8UNoz",
    "outputId": "3181f117-8f8e-495e-dd20-38c2940545ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "1.0\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
      "                     weights='uniform')\n",
      "0.9636363636363636\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.9454545454545454\n"
     ]
    }
   ],
   "source": [
    "topClassifier = None\n",
    "topScore = 0\n",
    "for classifier in topEstimator:\n",
    "    classifier.fit(X_feat_train, y_train)\n",
    "    y_prediction = classifier.predict(X_feat_val)\n",
    "    score = precision_score(y_val, y_prediction)\n",
    "    \n",
    "    if score > topScore:\n",
    "        topClassifier = classifier\n",
    "        topScore = score\n",
    "    \n",
    "    print (classifier)\n",
    "    print (score)\n",
    "#Esed the validation set with our top classifiers after removal of features below 25% correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58QYsX1yUNo2",
    "outputId": "a4a953c2-1fcc-4a7b-da39-fdf4f009696e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "0.9864864864864865\n"
     ]
    }
   ],
   "source": [
    "topClassifier.fit(X_feat_train, y_train)\n",
    "y_prediction = topClassifier.predict(X_feat_test)\n",
    "score = precision_score(y_test, y_prediction)\n",
    "print (topClassifier)\n",
    "print (score)\n",
    "#Used our best classifier(SVC) on our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end our best classification algoritm was SVC, it performed well on our training set, our validation set, and our test set. The scores for each respenctive set were: (1.0, 1.0, and 0.9864864864864865)\n",
    "\n",
    "It is interesting to note that our feature engineering had no discernable impact other than to make the training faster.\n",
    "\n",
    "It seems that using SVC with the same process of gathering data would be a highly accurate way to determine the type of tumor an individual has."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
